# =============================================================================
# üöÄ Mastra Agent Configuration - .env.example
# -----------------------------------------------------------------------------
# This environment file defines the necessary variables to run your AI agent
# either locally using Ollama or deployed remotely (e.g., on Nosana).
# =============================================================================

# -----------------------------------------------------------------------------
# üåê API_BASE_URL
# -----------------------------------------------------------------------------
# This is the base URL where the Large Language Model (LLM) API is running.
# When running locally using Ollama, set this to:
#   API_BASE_URL=http://localhost:11434/api
#
# When deploying on Nosana or using a remote LLM endpoint, replace <nosana-url>:
#   API_BASE_URL=https://<nosana-url>.node.k8s.prd.nos.ci/api
# -----------------------------------------------------------------------------
API_BASE_URL=
# -----------------------------------------------------------------------------
# ü§ñ MODEL_NAME_AT_ENDPOINT
# -----------------------------------------------------------------------------
# This is the name of the model that your agent will call through the API.
#
# For local development, use:
#   MODEL_NAME_AT_ENDPOINT=qwen2.5:1.5b
#
# For Nosana or cloud deployments with GPU support:
#   MODEL_NAME_AT_ENDPOINT=qwen3:8b
#
# ‚ö†Ô∏è Ensure the model you specify is available on the backend Ollama service.
# -----------------------------------------------------------------------------
MODEL_NAME_AT_ENDPOINT=

# -----------------------------------------------------------------------------
# ‚úÖ Notes:
# - When developing locally, use Ollama: https://ollama.com
#   > ollama serve
#   > ollama pull qwen2.5:1.5b
#
# - Make sure your `.env` file is created from this template:
#   cp .env.example .env
#
# - Do NOT commit your actual `.env` to source control for security reasons.
# -----------------------------------------------------------------------------
